services:
  vllm:
    build:
      context: .
      dockerfile: Dockerfile.vllm
    gpus: all
    environment:
      - HUGGING_FACE_HUB_TOKEN=
      - CUDA_VISIBLE_DEVICES=2,3
      - NVIDIA_VISIBLE_DEVICES=2,3
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - NCCL_IB_DISABLE=1
    command:
      - "--model=Qwen/Qwen3-4B"
      - "--dtype=bfloat16"
      - "--tensor-parallel-size=1"
      - "--gpu-memory-utilization=0.7"
      - "--max-model-len=4096"
      - "--port=8000"
    ports: ["8000:8000"]
    ipc: host
    volumes:
      - hf_cache:/root/.cache/huggingface
  rag-examplecompany:
    build: ./rag
    command: ["uvicorn","app:app","--host","0.0.0.0","--port","8080"]
    environment:
      - TENANT_ID=examplecompany
      - VLLM_BASE_URL=http://vllm:8000/v1
      - OPENAI_API_KEY=asd
    volumes:
      - ./data/example_company:/app/data:ro
      - indices_examplecompany:/app/indices
    ports: ["8101:8080"]

  rag-testcompany:
    build: ./rag
    command: ["uvicorn","app:app","--host","0.0.0.0","--port","8080"]
    environment:
      - TENANT_ID=testcompany
      - VLLM_BASE_URL=http://vllm:8000/v1
      - OPENAI_API_KEY=asd
    volumes:
      - ./data/test_company:/app/data:ro
      - indices_testcompany:/app/indices
    ports: ["8102:8080"]

  stt:
    build: ./stt
    gpus: all
    environment:
      - HF_HOME=/root/.cache/huggingface
      - HUGGING_FACE_HUB_TOKEN=
      - STT_DEVICE=auto
      - STT_COMPUTE_TYPE=auto
      - STT_MODEL_ID=sarpba/faster-base-hungarian_int8_V2
    volumes:
      - hf_cache:/root/.cache/huggingface
    ports: ["5001:5001"]

  tts:
    build: ./tts
    environment:
      - PIPER_VOICE=/voices/hu_HU-berta-medium.onnx
      - PIPER_VOICE_JSON=/voices/hu_HU-berta-medium.onnx.json
      - TTS_DEVICE=cpu               # set "cuda" to try GPU
    ports: ["5002:5002"]

  web-testcompany:
    build: ./web
    environment:
      - STT_URL=http://stt:5001/transcribe
      - RAG_URL=http://rag-testcompany:8080/query
      - TTS_URL=http://tts:5002/speak
      - COMPANY=testcompany
      - PORT=8090
    ports: ["8090:8090"]

  web-examplecompany:
    build: ./web
    environment:
      - STT_URL=http://stt:5001/transcribe
      - RAG_URL=http://rag-examplecompany:8080/query
      - TTS_URL=http://tts:5002/speak
      - COMPANY=examplecompany
      - PORT=8091
    ports: ["8091:8091"]

volumes:
  hf_cache:
  indices_examplecompany:
  indices_testcompany:
