# ğŸ—£ï¸ LLM Assistant for AI-Powered Customer Service Phone System

This project is an intelligent **AI Customer Service Phone Assistant**, tailored for **Hungarian-language** telephonic interactions. It integrates:

* ğŸ™ï¸ **Speech-to-Text (STT)** â€“ Fine-tuned Whisper Large
* ğŸ§  **Large Language Model (LLM)** â€“ currently via OpenAI API
* ğŸ”Š **Text-to-Speech (TTS)** â€“ Fine-tuned XTTS from Coqui

---

## ğŸ“ Project Structure

```
LLM-assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm.py          # Handles OpenAI LLM interactions
â”‚   â”‚   â”œâ”€â”€ stt.py          # Speech-to-Text processing
â”‚   â”‚   â”œâ”€â”€ tts.py          # Text-to-Speech processing
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ script.js       # Web client logic
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ index.html      # Web UI
â”‚   â”‚â”€â”€ __init__.py
â”‚   â”‚â”€â”€ config.py           # Configuration setup
â”‚   â”‚â”€â”€ routes.py           # Flask app routes
â”œâ”€â”€ uploads/                # Uploaded audio files (user input)
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ environment.yml
â”œâ”€â”€ main.py                 # Flask app entry
â”œâ”€â”€ requirements.txt
```

---

## ğŸš€ Getting Started

### ğŸ“¦ Local installation

```bash
# Using pip
pip install -r requirements.txt

# Or with conda
conda env create -f environment.yml
conda activate llm-assistant
```

### ğŸ Run the Application

```bash
python main.py
```

Open your browser at [http://localhost:5000](http://localhost:5000)

---

## ğŸ§  Component Overview

### ğŸ”Š Text-to-Speech (TTS)

Converts AI-generated text into **natural Hungarian speech**.

* âœ… **Currently using:** [Coqui XTTS](https://github.com/coqui-ai/TTS) with a **fine-tuned Hungarian model**
* ğŸ“¦ Supports expressive multilingual synthesis
* ğŸ’¡ XTTS enables cross-lingual transfer with high audio quality

**Alternatives explored:**

* F5 TTS â€“ Promising, with a story-telling style, but was abandoned due to slow procesing times
* google-tts â€“ Calls an online API
* facebook/mms-tts-hun - Doesn't sound that good

---

### ğŸ—£ï¸ Speech-to-Text (STT)

Transcribes **Hungarian spoken input** to text.

* âœ… **Currently using:** **Fine-tuned [Whisper Large](https://github.com/openai/whisper)** model for Hungarian
* ğŸ“ Local deployment for real-time performance
* ğŸ¯ Optimized for domain-specific (Hun/Eng, one at a time) customer service vocabulary

**Alternatives explored:**

* Multilanguage whisper â€“ Fast, lightweight, but picks up words from other languages

---

### ğŸ§  Large Language Model (LLM)

Provides the intelligence and conversation flow.

* âœ… **Currently using: OpenAI API**
* ğŸ’¬ Handles natural language understanding and response generation
* ğŸ§© Summarizes answers as to nat take too long on the phone

**Alternatives considered:**

*none - as of yet*

---

## ğŸ” Experimentation Summary
| Component | Methodology Explored                                         | Final Approach                      | Rationale                                                                                |
| --------- |--------------------------------------------------------------| ----------------------------------- | ---------------------------------------------------------------------------------------- |
| **TTS**   | Coqui XTTS, F5 TTS, google-tts, facebook/mms-tts-hun         | âœ… **Fine-tuned Coqui XTTS (HU)**    | Best-in-class Hungarian voice quality, expressive, multilingual support                  |
| **STT**   | Whisper Large (multilingual)                                 | âœ… **Fine-tuned Whisper Large (HU)** | High accuracy and real-time performance for Hungarian customer service use               |
| **LLM**   | OpenAI GPT-4  | âœ… **OpenAI GPT-3.5 API**            | Reliable generation, robust dialogue management; future-proof for fallback to local LLMs |

---

## ğŸ’¡ Potential Future Enhancements

* ğŸ“ Integrate **SIP/VoIP** for real phone calls (e.g. Twilio)
* ğŸ§  Add **RAG** integration for retrieval-augmented responses
* ğŸ“ˆ Add calendar and other system integration tools, maybe Agent-to-Agent protocol
* ğŸ” Move LLM inference to **on-premise or private cloud** and multi-containerize the application
* ğŸ—£ï¸ Support multilingual switching in real-time

---

## ğŸ›¡ï¸ Environment & Deployment

### Environment Variables (`.env`)

```
OPENAI_API_KEY=your_openai_api_key
UPLOAD_FOLDER=uploads_folder_location
STATIC_FOLDER=static_folder_location
DEBUG=whether_to_enable_debug_mode
```

### Docker Support

```bash
docker build -t llm-assistant .
docker run -p 5000:5000 llm-assistant
```

or you may pull it from dockerhub, it's publicly available at [pdwn/assistant:latest](https://hub.docker.com/r/pdwn/assistant)

```bash
docker pull pdwn/assistant:latest
```
---

## ğŸ“¬ Contact

Have questions or suggestions? Open an issue or reach out directly.
